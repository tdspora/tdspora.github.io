"use strict";(self.webpackChunktdm_docs=self.webpackChunktdm_docs||[]).push([[223],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>m});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(a),m=r,f=d["".concat(s,".").concat(m)]||d[m]||u[m]||o;return a?n.createElement(f,i(i({ref:t},c),{},{components:a})):n.createElement(f,i({ref:t},c))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},8650:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var n=a(7462),r=(a(7294),a(3905));const o={title:"Dynamic allocation of executors"},i=void 0,l={unversionedId:"troubleshooting/dynamic-resource-allocation-failed",id:"troubleshooting/dynamic-resource-allocation-failed",title:"Dynamic allocation of executors",description:"In case of\xa0--conf spark.dynamicAllocation.enabled=true, we get the error on worker:",source:"@site/docs/troubleshooting/dynamic-resource-allocation-failed.md",sourceDirName:"troubleshooting",slug:"/troubleshooting/dynamic-resource-allocation-failed",permalink:"/docs/troubleshooting/dynamic-resource-allocation-failed",draft:!1,tags:[],version:"current",frontMatter:{title:"Dynamic allocation of executors"},sidebar:"docs",previous:{title:"PostgreSQL - disable triggers",permalink:"/docs/troubleshooting/connectivity-postgresql-disable-triggers"},next:{title:"End User License Agreement",permalink:"/docs/legal/EULA"}},s={},p=[],c={toc:p};function u(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"In case of\xa0--conf spark.dynamicAllocation.enabled=true, we get the error on worker:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"ERROR SparkContext: Error initializing SparkContext.\norg.apache.spark.SparkException: Dynamic allocation of executors requires the external shuffle service.\nYou may enable this through spark.shuffle.service.enabled.\n    at org.apache.spark.ExecutorAllocationManager.validateSettings(ExecutorAllocationManager.scala:214)\n    at org.apache.spark.ExecutorAllocationManager.<init>(ExecutorAllocationManager.scala:135)\n    at org.apache.spark.SparkContext.<init>(SparkContext.scala:626)\n    at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2678)\n    at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:942)\n    at scala.Option.getOrElse(Option.scala:189)\n    at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:936)\n    at com.epam.tdm.engine.TdmEngineJobApp$.$anonfun$main$1(TdmEngineJobApp.scala:110)\n    at scala.util.Using$.$anonfun$apply$1(Using.scala:115)\n    at scala.util.Try$.apply(Try.scala:213)\n    at scala.util.Using$.apply(Using.scala:115)\n    at com.epam.tdm.engine.TdmEngineJobApp$.main(TdmEngineJobApp.scala:110)\n    at com.epam.tdm.engine.TdmEngineJobApp.main(TdmEngineJobApp.scala)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.apache.spark.deploy.worker.DriverWrapper$.main(DriverWrapper.scala:65)\n    at org.apache.spark.deploy.worker.DriverWrapper.main(DriverWrapper.scala)\n")),(0,r.kt)("p",null,"From:\xa0",(0,r.kt)("a",{parentName:"p",href:"https://community.cloudera.com/t5/Support-Questions/Spark-dynamic-allocation-dont-work/td-p/140227"},"https://community.cloudera.com/t5/Support-Questions/Spark-dynamic-allocation-dont-work/td-p/140227")),(0,r.kt)("p",null,"Documentation about Dynamic Execution says the following (",(0,r.kt)("strong",{parentName:"p"},"bold")," mine):"),(0,r.kt)("p",null,"There are ",(0,r.kt)("strong",{parentName:"p"},"two")," requirements for using this feature. ",(0,r.kt)("strong",{parentName:"p"},"First"),", your application must set ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.dynamicAllocation.enabled")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"true"),". ",(0,r.kt)("strong",{parentName:"p"},"Second"),", you must set up an ",(0,r.kt)("em",{parentName:"p"},"external shuffle service")," on each worker node in the same cluster and set ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.shuffle.service.enabled")," to true in your application. The purpose of the external shuffle service is to allow executors to be removed without deleting shuffle files written by them (more detail described ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/job-scheduling.html#graceful-decommission-of-executors"},"below"),"). The way to set up this service varies across cluster managers:"),(0,r.kt)("p",null,"In standalone mode, simply start your workers with ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.shuffle.service.enabled")," set to ",(0,r.kt)("inlineCode",{parentName:"p"},"true"),"."),(0,r.kt)("p",null,"In Mesos coarse-grained mode, run ",(0,r.kt)("inlineCode",{parentName:"p"},"$SPARK_HOME/sbin/start-mesos-shuffle-service.sh")," on all slave nodes with ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.shuffle.service.enabled")," set to ",(0,r.kt)("inlineCode",{parentName:"p"},"true"),". For instance, you may do so through Marathon."),(0,r.kt)("p",null,"In YARN mode, start the shuffle service on each ",(0,r.kt)("inlineCode",{parentName:"p"},"NodeManager")," as follows:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Build Spark with the ",(0,r.kt)("a",{parentName:"li",href:"https://spark.apache.org/docs/latest/building-spark.html"},"YARN profile"),". Skip this step if you are using a pre-packaged distribution."),(0,r.kt)("li",{parentName:"ol"},"Locate the ",(0,r.kt)("inlineCode",{parentName:"li"},"spark-<version>-yarn-shuffle.jar"),". This should be under ",(0,r.kt)("inlineCode",{parentName:"li"},"$SPARK_HOME/network/yarn/target/scala-<version>")," if you are building Spark yourself, and under ",(0,r.kt)("inlineCode",{parentName:"li"},"lib")," if you are using a distribution."),(0,r.kt)("li",{parentName:"ol"},"Add this jar to the classpath of all ",(0,r.kt)("inlineCode",{parentName:"li"},"NodeManager"),"s in your cluster."),(0,r.kt)("li",{parentName:"ol"},"In the ",(0,r.kt)("inlineCode",{parentName:"li"},"yarn-site.xml")," on each node, add ",(0,r.kt)("inlineCode",{parentName:"li"},"spark_shuffle")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"yarn.nodemanager.aux-services"),", then set ",(0,r.kt)("inlineCode",{parentName:"li"},"yarn.nodemanager.aux-services.spark_shuffle.class")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"org.apache.spark.network.yarn.YarnShuffleService"),"."),(0,r.kt)("li",{parentName:"ol"},"Restart all ",(0,r.kt)("inlineCode",{parentName:"li"},"NodeManager"),"s in your cluster.")),(0,r.kt)("p",null,"All other relevant configurations are optional and under the ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.dynamicAllocation.*")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"spark.shuffle.service.*")," namespaces. For more detail, see the ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/configuration.html#dynamic-allocation"},"configurations page"),"."),(0,r.kt)("p",null,"Reference Link:"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation"},"https://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation")))}u.isMDXComponent=!0}}]);