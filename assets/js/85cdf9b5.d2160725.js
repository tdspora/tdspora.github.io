"use strict";(self.webpackChunktdm_docs=self.webpackChunktdm_docs||[]).push([[252],{5788:(e,a,n)=>{n.d(a,{Iu:()=>c,yg:()=>m});var t=n(1504);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function o(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function i(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?o(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function l(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)n=o[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=t.createContext({}),p=function(e){var a=t.useContext(s),n=a;return e&&(n="function"==typeof e?e(a):i(i({},a),e)),n},c=function(e){var a=p(e.components);return t.createElement(s.Provider,{value:a},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},g=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),u=p(n),g=r,m=u["".concat(s,".").concat(g)]||u[g]||d[g]||o;return n?t.createElement(m,i(i({ref:a},c),{},{components:n})):t.createElement(m,i({ref:a},c))}));function m(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=g;var l={};for(var s in a)hasOwnProperty.call(a,s)&&(l[s]=a[s]);l.originalType=e,l[u]="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return t.createElement.apply(null,i)}return t.createElement.apply(null,n)}g.displayName="MDXCreateElement"},1228:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var t=n(5072),r=(n(1504),n(5788));const o={title:"Dynamic allocation of executors"},i=void 0,l={unversionedId:"troubleshooting/dynamic-resource-allocation-failed",id:"troubleshooting/dynamic-resource-allocation-failed",title:"Dynamic allocation of executors",description:"In case of\xa0--conf spark.dynamicAllocation.enabled=true, we get the error on worker:",source:"@site/docs/troubleshooting/dynamic-resource-allocation-failed.md",sourceDirName:"troubleshooting",slug:"/troubleshooting/dynamic-resource-allocation-failed",permalink:"/docs/troubleshooting/dynamic-resource-allocation-failed",draft:!1,tags:[],version:"current",frontMatter:{title:"Dynamic allocation of executors"},sidebar:"docs",previous:{title:"PostgreSQL - disable triggers",permalink:"/docs/troubleshooting/connectivity-postgresql-disable-triggers"},next:{title:"End User License Agreement",permalink:"/docs/legal/EULA"}},s={},p=[],c={toc:p},u="wrapper";function d(e){let{components:a,...n}=e;return(0,r.yg)(u,(0,t.c)({},c,n,{components:a,mdxType:"MDXLayout"}),(0,r.yg)("p",null,"In case of\xa0--conf spark.dynamicAllocation.enabled=true, we get the error on worker:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre"},"ERROR SparkContext: Error initializing SparkContext.\norg.apache.spark.SparkException: Dynamic allocation of executors requires the external shuffle service.\nYou may enable this through spark.shuffle.service.enabled.\n    at org.apache.spark.ExecutorAllocationManager.validateSettings(ExecutorAllocationManager.scala:214)\n    at org.apache.spark.ExecutorAllocationManager.<init>(ExecutorAllocationManager.scala:135)\n    at org.apache.spark.SparkContext.<init>(SparkContext.scala:626)\n    at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2678)\n    at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:942)\n    at scala.Option.getOrElse(Option.scala:189)\n    at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:936)\n    at com.epam.tdm.engine.TdmEngineJobApp$.$anonfun$main$1(TdmEngineJobApp.scala:110)\n    at scala.util.Using$.$anonfun$apply$1(Using.scala:115)\n    at scala.util.Try$.apply(Try.scala:213)\n    at scala.util.Using$.apply(Using.scala:115)\n    at com.epam.tdm.engine.TdmEngineJobApp$.main(TdmEngineJobApp.scala:110)\n    at com.epam.tdm.engine.TdmEngineJobApp.main(TdmEngineJobApp.scala)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.apache.spark.deploy.worker.DriverWrapper$.main(DriverWrapper.scala:65)\n    at org.apache.spark.deploy.worker.DriverWrapper.main(DriverWrapper.scala)\n")),(0,r.yg)("p",null,"From:\xa0",(0,r.yg)("a",{parentName:"p",href:"https://community.cloudera.com/t5/Support-Questions/Spark-dynamic-allocation-dont-work/td-p/140227"},"https://community.cloudera.com/t5/Support-Questions/Spark-dynamic-allocation-dont-work/td-p/140227")),(0,r.yg)("p",null,"Documentation about Dynamic Execution says the following (",(0,r.yg)("strong",{parentName:"p"},"bold")," mine):"),(0,r.yg)("p",null,"There are ",(0,r.yg)("strong",{parentName:"p"},"two")," requirements for using this feature. ",(0,r.yg)("strong",{parentName:"p"},"First"),", your application must set ",(0,r.yg)("inlineCode",{parentName:"p"},"spark.dynamicAllocation.enabled")," to ",(0,r.yg)("inlineCode",{parentName:"p"},"true"),". ",(0,r.yg)("strong",{parentName:"p"},"Second"),", you must set up an ",(0,r.yg)("em",{parentName:"p"},"external shuffle service")," on each worker node in the same cluster and set ",(0,r.yg)("inlineCode",{parentName:"p"},"spark.shuffle.service.enabled")," to true in your application. The purpose of the external shuffle service is to allow executors to be removed without deleting shuffle files written by them (more detail described ",(0,r.yg)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/job-scheduling.html#graceful-decommission-of-executors"},"below"),"). The way to set up this service varies across cluster managers:"),(0,r.yg)("p",null,"In standalone mode, simply start your workers with ",(0,r.yg)("inlineCode",{parentName:"p"},"spark.shuffle.service.enabled")," set to ",(0,r.yg)("inlineCode",{parentName:"p"},"true"),"."),(0,r.yg)("p",null,"In Mesos coarse-grained mode, run ",(0,r.yg)("inlineCode",{parentName:"p"},"$SPARK_HOME/sbin/start-mesos-shuffle-service.sh")," on all slave nodes with ",(0,r.yg)("inlineCode",{parentName:"p"},"spark.shuffle.service.enabled")," set to ",(0,r.yg)("inlineCode",{parentName:"p"},"true"),". For instance, you may do so through Marathon."),(0,r.yg)("p",null,"In YARN mode, start the shuffle service on each ",(0,r.yg)("inlineCode",{parentName:"p"},"NodeManager")," as follows:"),(0,r.yg)("ol",null,(0,r.yg)("li",{parentName:"ol"},"Build Spark with the ",(0,r.yg)("a",{parentName:"li",href:"https://spark.apache.org/docs/latest/building-spark.html"},"YARN profile"),". Skip this step if you are using a pre-packaged distribution."),(0,r.yg)("li",{parentName:"ol"},"Locate the ",(0,r.yg)("inlineCode",{parentName:"li"},"spark-<version>-yarn-shuffle.jar"),". This should be under ",(0,r.yg)("inlineCode",{parentName:"li"},"$SPARK_HOME/network/yarn/target/scala-<version>")," if you are building Spark yourself, and under ",(0,r.yg)("inlineCode",{parentName:"li"},"lib")," if you are using a distribution."),(0,r.yg)("li",{parentName:"ol"},"Add this jar to the classpath of all ",(0,r.yg)("inlineCode",{parentName:"li"},"NodeManager"),"s in your cluster."),(0,r.yg)("li",{parentName:"ol"},"In the ",(0,r.yg)("inlineCode",{parentName:"li"},"yarn-site.xml")," on each node, add ",(0,r.yg)("inlineCode",{parentName:"li"},"spark_shuffle")," to ",(0,r.yg)("inlineCode",{parentName:"li"},"yarn.nodemanager.aux-services"),", then set ",(0,r.yg)("inlineCode",{parentName:"li"},"yarn.nodemanager.aux-services.spark_shuffle.class")," to ",(0,r.yg)("inlineCode",{parentName:"li"},"org.apache.spark.network.yarn.YarnShuffleService"),"."),(0,r.yg)("li",{parentName:"ol"},"Restart all ",(0,r.yg)("inlineCode",{parentName:"li"},"NodeManager"),"s in your cluster.")),(0,r.yg)("p",null,"All other relevant configurations are optional and under the ",(0,r.yg)("inlineCode",{parentName:"p"},"spark.dynamicAllocation.*")," and ",(0,r.yg)("inlineCode",{parentName:"p"},"spark.shuffle.service.*")," namespaces. For more detail, see the ",(0,r.yg)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/configuration.html#dynamic-allocation"},"configurations page"),"."),(0,r.yg)("p",null,"Reference Link:"),(0,r.yg)("p",null,(0,r.yg)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation"},"https://spark.apache.org/docs/latest/job-scheduling.html#dynamic-resource-allocation")))}d.isMDXComponent=!0}}]);